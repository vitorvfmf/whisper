{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5hvo8QWN-a9"
   },
   "source": [
    "# Installing Whisper\n",
    "\n",
    "The commands below will install the Python packages needed to use Whisper models and evaluate the transcription results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZsJUxc0aRsAf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to c:\\users\\fernav4\\appdata\\local\\temp\\pip-req-build-xr1xtmm8\n",
      "  Resolved https://github.com/openai/whisper.git to commit e8622f9afc4eba139bf796c210f5c01081000472\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting numba (from openai-whisper==20230314)\n",
      "  Obtaining dependency information for numba from https://files.pythonhosted.org/packages/f3/3e/6349c624303b78b6bbb97168c7fb38a1a0cb1605ae4c5d45af3b829f067a/numba-0.57.1-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading numba-0.57.1-cp310-cp310-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting numpy (from openai-whisper==20230314)\n",
      "  Obtaining dependency information for numpy from https://files.pythonhosted.org/packages/b7/db/4d37359e2c9cf8bf071c08b8a6f7374648a5ab2e76e2e22e3b808f81d507/numpy-1.25.2-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading numpy-1.25.2-cp310-cp310-win_amd64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\fernav4\\appdata\\roaming\\python\\python310\\site-packages (from openai-whisper==20230314) (2.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\fernav4\\appdata\\roaming\\python\\python310\\site-packages (from openai-whisper==20230314) (4.65.0)\n",
      "Collecting more-itertools (from openai-whisper==20230314)\n",
      "  Obtaining dependency information for more-itertools from https://files.pythonhosted.org/packages/5a/cb/6dce742ea14e47d6f565589e859ad225f2a5de576d7696e0623b784e226b/more_itertools-10.1.0-py3-none-any.whl.metadata\n",
      "  Downloading more_itertools-10.1.0-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting tiktoken==0.3.3 (from openai-whisper==20230314)\n",
      "  Downloading tiktoken-0.3.3-cp310-cp310-win_amd64.whl (579 kB)\n",
      "     ---------------------------------------- 0.0/579.4 kB ? eta -:--:--\n",
      "     ------------------------------- ----- 491.5/579.4 kB 10.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- 579.4/579.4 kB 7.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\fernav4\\appdata\\roaming\\python\\python310\\site-packages (from tiktoken==0.3.3->openai-whisper==20230314) (2023.3.22)\n",
      "Collecting requests>=2.26.0 (from tiktoken==0.3.3->openai-whisper==20230314)\n",
      "  Obtaining dependency information for requests>=2.26.0 from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting llvmlite<0.41,>=0.40.0dev0 (from numba->openai-whisper==20230314)\n",
      "  Obtaining dependency information for llvmlite<0.41,>=0.40.0dev0 from https://files.pythonhosted.org/packages/6c/4f/e6f9dc0b34e5b8450ef757cd35afda999c8cc5098907a512cf0ecae840b5/llvmlite-0.40.1-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading llvmlite-0.40.1-cp310-cp310-win_amd64.whl.metadata (4.8 kB)\n",
      "Collecting numpy (from openai-whisper==20230314)\n",
      "  Obtaining dependency information for numpy from https://files.pythonhosted.org/packages/22/55/3d5a7c1142e0d9329ad27cece17933b0e2ab4e54ddc5c1861fbfeb3f7693/numpy-1.24.4-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading numpy-1.24.4-cp310-cp310-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\fernav4\\appdata\\roaming\\python\\python310\\site-packages (from torch->openai-whisper==20230314) (3.10.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\fernav4\\.conda\\envs\\whisper\\lib\\site-packages (from torch->openai-whisper==20230314) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\fernav4\\appdata\\roaming\\python\\python310\\site-packages (from torch->openai-whisper==20230314) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\fernav4\\appdata\\roaming\\python\\python310\\site-packages (from torch->openai-whisper==20230314) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\fernav4\\.conda\\envs\\whisper\\lib\\site-packages (from torch->openai-whisper==20230314) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\fernav4\\.conda\\envs\\whisper\\lib\\site-packages (from tqdm->openai-whisper==20230314) (0.4.6)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314)\n",
      "  Obtaining dependency information for charset-normalizer<4,>=2 from https://files.pythonhosted.org/packages/5c/f2/f3faa20684729d3910af2ee142e30432c7a46a817eadeeab87366ed87bbb/charset_normalizer-3.2.0-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading charset_normalizer-3.2.0-cp310-cp310-win_amd64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fernav4\\.conda\\envs\\whisper\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (3.4)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314)\n",
      "  Obtaining dependency information for urllib3<3,>=1.21.1 from https://files.pythonhosted.org/packages/9b/81/62fd61001fa4b9d0df6e31d47ff49cfa9de4af03adecf339c7bc30656b37/urllib3-2.0.4-py3-none-any.whl.metadata\n",
      "  Downloading urllib3-2.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314)\n",
      "  Obtaining dependency information for certifi>=2017.4.17 from https://files.pythonhosted.org/packages/4c/dd/2234eab22353ffc7d94e8d13177aaa050113286e93e7b40eae01fbf7c3d9/certifi-2023.7.22-py3-none-any.whl.metadata\n",
      "  Downloading certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\fernav4\\.conda\\envs\\whisper\\lib\\site-packages (from jinja2->torch->openai-whisper==20230314) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\fernav4\\appdata\\roaming\\python\\python310\\site-packages (from sympy->torch->openai-whisper==20230314) (1.3.0)\n",
      "Downloading more_itertools-10.1.0-py3-none-any.whl (55 kB)\n",
      "   ---------------------------------------- 0.0/55.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 55.8/55.8 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading numba-0.57.1-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.7/2.5 MB 20.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.2/2.5 MB 13.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.7/2.5 MB 13.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.3/2.5 MB 13.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 MB 12.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 10.8 MB/s eta 0:00:00\n",
      "Downloading numpy-1.24.4-cp310-cp310-win_amd64.whl (14.8 MB)\n",
      "   ---------------------------------------- 0.0/14.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.6/14.8 MB 18.5 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 1.1/14.8 MB 14.3 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.7/14.8 MB 13.4 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 2.2/14.8 MB 12.9 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.8/14.8 MB 12.7 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 3.3/14.8 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.9/14.8 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 4.4/14.8 MB 12.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 5.0/14.8 MB 12.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 5.5/14.8 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.0/14.8 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 6.6/14.8 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.2/14.8 MB 12.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 7.7/14.8 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.3/14.8 MB 12.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 8.8/14.8 MB 12.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.3/14.8 MB 12.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.9/14.8 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.5/14.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.0/14.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.5/14.8 MB 11.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.1/14.8 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.6/14.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.1/14.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.7/14.8 MB 11.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.2/14.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.8/14.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.8/14.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.8/14.8 MB 10.6 MB/s eta 0:00:00\n",
      "Downloading llvmlite-0.40.1-cp310-cp310-win_amd64.whl (27.7 MB)\n",
      "   ---------------------------------------- 0.0/27.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.6/27.7 MB 12.9 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 1.2/27.7 MB 12.2 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.7/27.7 MB 12.1 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 2.2/27.7 MB 13.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 2.8/27.7 MB 12.7 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 3.3/27.7 MB 12.5 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 3.9/27.7 MB 11.8 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.4/27.7 MB 12.3 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 5.0/27.7 MB 12.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 5.5/27.7 MB 12.1 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 6.1/27.7 MB 12.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 6.6/27.7 MB 12.0 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 7.1/27.7 MB 12.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 7.7/27.7 MB 12.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 8.2/27.7 MB 12.0 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 8.8/27.7 MB 11.9 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 9.3/27.7 MB 11.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 9.9/27.7 MB 11.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 10.4/27.7 MB 11.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 11.0/27.7 MB 11.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 11.5/27.7 MB 11.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 12.1/27.7 MB 11.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 12.6/27.7 MB 11.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 13.1/27.7 MB 11.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 13.7/27.7 MB 11.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 14.2/27.7 MB 11.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 14.8/27.7 MB 11.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 15.3/27.7 MB 11.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 15.9/27.7 MB 11.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 16.5/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 17.0/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 17.6/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 18.1/27.7 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 18.6/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 19.2/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 19.7/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 20.3/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 20.8/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 21.4/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 21.9/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 22.5/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 23.0/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 23.5/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 24.1/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 24.6/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 25.2/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 25.7/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 26.3/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 26.8/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  27.4/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  27.7/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  27.7/27.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 27.7/27.7 MB 10.2 MB/s eta 0:00:00\n",
      "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.6/62.6 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "   ---------------------------------------- 0.0/158.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 158.3/158.3 kB 9.3 MB/s eta 0:00:00\n",
      "Downloading charset_normalizer-3.2.0-cp310-cp310-win_amd64.whl (96 kB)\n",
      "   ---------------------------------------- 0.0/96.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 96.9/96.9 kB 2.8 MB/s eta 0:00:00\n",
      "Downloading urllib3-2.0.4-py3-none-any.whl (123 kB)\n",
      "   ---------------------------------------- 0.0/123.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 123.9/123.9 kB 7.1 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml): started\n",
      "  Building wheel for openai-whisper (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=807707 sha256=ddaa15867d90108ba7f1723df44aa4444345664aec006290420a4fced1d6309d\n",
      "  Stored in directory: C:\\Users\\fernav4\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-w21o7cbx\\wheels\\8b\\6c\\d0\\622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: urllib3, numpy, more-itertools, llvmlite, charset-normalizer, certifi, requests, numba, tiktoken, openai-whisper\n",
      "Successfully installed certifi-2023.7.22 charset-normalizer-3.2.0 llvmlite-0.40.1 more-itertools-10.1.0 numba-0.57.1 numpy-1.24.4 openai-whisper-20230314 requests-2.31.0 tiktoken-0.3.3 urllib3-2.0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git 'C:\\Users\\fernav4\\AppData\\Local\\Temp\\pip-req-build-xr1xtmm8'\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "huggingface-hub 0.13.3 requires pyyaml>=5.1, which is not installed.\n",
      "tensorflow-hub 0.13.0 requires protobuf>=3.19.6, which is not installed.\n",
      "transformers 4.27.2 requires pyyaml>=5.1, which is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jiwer\n",
      "  Obtaining dependency information for jiwer from https://files.pythonhosted.org/packages/23/a3/92c29a5e422acd87e3b4f2e6dc0ce877070cc9b2f81d30fe84122032338a/jiwer-3.0.2-py3-none-any.whl.metadata\n",
      "  Downloading jiwer-3.0.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in c:\\users\\fernav4\\appdata\\roaming\\python\\python310\\site-packages (from jiwer) (8.1.3)\n",
      "Collecting rapidfuzz==2.13.7 (from jiwer)\n",
      "  Downloading rapidfuzz-2.13.7-cp310-cp310-win_amd64.whl (1.0 MB)\n",
      "     ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.1/1.0 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 0.4/1.0 MB 5.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 1.0/1.0 MB 7.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.0/1.0 MB 6.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\fernav4\\.conda\\envs\\whisper\\lib\\site-packages (from click<9.0.0,>=8.1.3->jiwer) (0.4.6)\n",
      "Downloading jiwer-3.0.2-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: rapidfuzz, jiwer\n",
      "Successfully installed jiwer-3.0.2 rapidfuzz-2.13.7\n"
     ]
    }
   ],
   "source": [
    "! pip install git+https://github.com/openai/whisper.git\n",
    "! pip install jiwer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IMEkgyagYto"
   },
   "source": [
    "# Loading the LibriSpeech dataset\n",
    "\n",
    "The following will load the test-clean split of the LibriSpeech corpus using torchaudio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchaudioNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached torchaudio-2.0.2-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "Requirement already satisfied: torch==2.0.1 in c:\\users\\fernav4\\.conda\\envs\\whisper\\lib\\site-packages (from torchaudio) (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\fernav4\\appdata\\roaming\\python\\python310\\site-packages (from torch==2.0.1->torchaudio) (3.10.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\fernav4\\.conda\\envs\\whisper\\lib\\site-packages (from torch==2.0.1->torchaudio) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\fernav4\\appdata\\roaming\\python\\python310\\site-packages (from torch==2.0.1->torchaudio) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\fernav4\\appdata\\roaming\\python\\python310\\site-packages (from torch==2.0.1->torchaudio) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\fernav4\\.conda\\envs\\whisper\\lib\\site-packages (from torch==2.0.1->torchaudio) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\fernav4\\.conda\\envs\\whisper\\lib\\site-packages (from jinja2->torch==2.0.1->torchaudio) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\fernav4\\appdata\\roaming\\python\\python310\\site-packages (from sympy->torch==2.0.1->torchaudio) (1.3.0)\n",
      "Installing collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.0.2\n"
     ]
    }
   ],
   "source": [
    "pip install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3CqtR2Fi5-vP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fernav4\\.conda\\envs\\whisper\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import tensorflow  # required in Colab to avoid protobuf compatibility issues\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import whisper\n",
    "import torchaudio\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GuCCB2KYOJCE"
   },
   "outputs": [],
   "source": [
    "class LibriSpeech(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A simple class to wrap LibriSpeech and trim/pad the audio to 30 seconds.\n",
    "    It will drop the last few seconds of a very small portion of the utterances.\n",
    "    \"\"\"\n",
    "    def __init__(self, split=\"test-clean\", device=DEVICE):\n",
    "        self.dataset = torchaudio.datasets.LIBRISPEECH(\n",
    "            root=os.path.expanduser(\"~/.cache\"),\n",
    "            url=split,\n",
    "            download=True,\n",
    "        )\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        audio, sample_rate, text, _, _, _ = self.dataset[item]\n",
    "        assert sample_rate == 16000\n",
    "        audio = whisper.pad_or_trim(audio.flatten()).to(self.device)\n",
    "        mel = whisper.log_mel_spectrogram(audio)\n",
    "        \n",
    "        return (mel, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-YcRU5jqNqo2"
   },
   "outputs": [],
   "source": [
    "dataset = LibriSpeech(\"test-clean\")\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ljocCNuUAde"
   },
   "source": [
    "# Running inference on the dataset using a base Whisper model\n",
    "\n",
    "The following will take a few minutes to transcribe all utterances in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_PokfNJtOYNu",
    "outputId": "2c53ec44-bc93-4107-b4fa-214e3f71fe8e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 139M/139M [00:13<00:00, 11.0MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is English-only and has 71,825,408 parameters.\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"base.en\")\n",
    "print(\n",
    "    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
    "    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict without timestamps for short-form transcription\n",
    "options = whisper.DecodingOptions(language=\"en\", without_timestamps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "09a29a91f58d4462942505a3cc415801",
      "83391f98a240490987c397048fc1a0d4",
      "06b9aa5f49fa44ba8c93b647dc7db224",
      "da9c231ee67047fb89073c95326b72a5",
      "48da931ebe7f4fd299f8c98c7d2460ff",
      "7a901f447c1d477bb49f954e0feacedd",
      "39f5a6ae8ba74c8598f9c6d5b8ad2d65",
      "a0d10a42c753453283e5219c22239337",
      "09f4cb79ff86465aaf48b0de24869af9",
      "1b9cecf5b3584fba8258a81d4279a25b",
      "039b53f2702c4179af7e0548018d0588"
     ]
    },
    "id": "7OWTn_KvNk59",
    "outputId": "a813a792-3c91-4144-f11f-054fd6778023"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m hypotheses \u001b[39m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m references \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m mels, texts \u001b[39min\u001b[39;00m tqdm(loader):\n\u001b[0;32m      5\u001b[0m     results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mdecode(mels, options)\n\u001b[0;32m      6\u001b[0m     hypotheses\u001b[39m.\u001b[39mextend([result\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m results])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\notebook.py:238\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m unit_scale \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munit_scale \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munit_scale \u001b[39mor\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[0;32m    237\u001b[0m total \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal \u001b[39m*\u001b[39m unit_scale \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal\n\u001b[1;32m--> 238\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstatus_printer(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp, total, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdesc, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mncols)\n\u001b[0;32m    239\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontainer\u001b[39m.\u001b[39mpbar \u001b[39m=\u001b[39m proxy(\u001b[39mself\u001b[39m)\n\u001b[0;32m    240\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisplayed \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\notebook.py:113\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[39m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[39m# if not total:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m \n\u001b[0;32m    111\u001b[0m \u001b[39m# Prepare IPython progress bar\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[39mif\u001b[39;00m IProgress \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# #187 #451 #558 #872\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[0;32m    114\u001b[0m \u001b[39mif\u001b[39;00m total:\n\u001b[0;32m    115\u001b[0m     pbar \u001b[39m=\u001b[39m IProgress(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39mmax\u001b[39m\u001b[39m=\u001b[39mtotal)\n",
      "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "hypotheses = []\n",
    "references = []\n",
    "\n",
    "for mels, texts in tqdm(loader):\n",
    "    results = model.decode(mels, options)\n",
    "    hypotheses.extend([result.text for result in results])\n",
    "    references.extend(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "4nTyynELQ42j",
    "outputId": "1c72d25a-3e87-4c60-a8d1-1da9d2f73bd7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He hoped there would be stew for dinner, turni...</td>\n",
       "      <td>HE HOPED THERE WOULD BE STEW FOR DINNER TURNIP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stuffered into you, his belly counseled him.</td>\n",
       "      <td>STUFF IT INTO YOU HIS BELLY COUNSELLED HIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After early nightfall the yellow lamps would l...</td>\n",
       "      <td>AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello Bertie, any good in your mind?</td>\n",
       "      <td>HELLO BERTIE ANY GOOD IN YOUR MIND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Number 10. Fresh Nelly is waiting on you. Good...</td>\n",
       "      <td>NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>Oh, to shoot my soul's full meaning into futur...</td>\n",
       "      <td>OH TO SHOOT MY SOUL'S FULL MEANING INTO FUTURE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>Then I, long tried by natural ills, received t...</td>\n",
       "      <td>THEN I LONG TRIED BY NATURAL ILLS RECEIVED THE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>I love thee freely as men strive for right. I ...</td>\n",
       "      <td>I LOVE THEE FREELY AS MEN STRIVE FOR RIGHT I L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>I love thee with the passion put to use, in my...</td>\n",
       "      <td>I LOVE THEE WITH THE PASSION PUT TO USE IN MY ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>I love thee with the love I seemed to lose wit...</td>\n",
       "      <td>I LOVE THEE WITH A LOVE I SEEMED TO LOSE WITH ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2620 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             hypothesis  \\\n",
       "0     He hoped there would be stew for dinner, turni...   \n",
       "1          Stuffered into you, his belly counseled him.   \n",
       "2     After early nightfall the yellow lamps would l...   \n",
       "3                  Hello Bertie, any good in your mind?   \n",
       "4     Number 10. Fresh Nelly is waiting on you. Good...   \n",
       "...                                                 ...   \n",
       "2615  Oh, to shoot my soul's full meaning into futur...   \n",
       "2616  Then I, long tried by natural ills, received t...   \n",
       "2617  I love thee freely as men strive for right. I ...   \n",
       "2618  I love thee with the passion put to use, in my...   \n",
       "2619  I love thee with the love I seemed to lose wit...   \n",
       "\n",
       "                                              reference  \n",
       "0     HE HOPED THERE WOULD BE STEW FOR DINNER TURNIP...  \n",
       "1            STUFF IT INTO YOU HIS BELLY COUNSELLED HIM  \n",
       "2     AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD L...  \n",
       "3                    HELLO BERTIE ANY GOOD IN YOUR MIND  \n",
       "4     NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD ...  \n",
       "...                                                 ...  \n",
       "2615  OH TO SHOOT MY SOUL'S FULL MEANING INTO FUTURE...  \n",
       "2616  THEN I LONG TRIED BY NATURAL ILLS RECEIVED THE...  \n",
       "2617  I LOVE THEE FREELY AS MEN STRIVE FOR RIGHT I L...  \n",
       "2618  I LOVE THEE WITH THE PASSION PUT TO USE IN MY ...  \n",
       "2619  I LOVE THEE WITH A LOVE I SEEMED TO LOSE WITH ...  \n",
       "\n",
       "[2620 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPppEJRXX4ox"
   },
   "source": [
    "# Calculating the word error rate\n",
    "\n",
    "Now, we use our English normalizer implementation to standardize the transcription and calculate the WER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dl-KBDflMhrg"
   },
   "outputs": [],
   "source": [
    "import jiwer\n",
    "from whisper.normalizers import EnglishTextNormalizer\n",
    "\n",
    "normalizer = EnglishTextNormalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "6-O048q4WI4o",
    "outputId": "f2089bc9-f535-441e-f192-26e52ae82b5e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>reference</th>\n",
       "      <th>hypothesis_clean</th>\n",
       "      <th>reference_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He hoped there would be stew for dinner, turni...</td>\n",
       "      <td>HE HOPED THERE WOULD BE STEW FOR DINNER TURNIP...</td>\n",
       "      <td>he hoped there would be stew for dinner turnip...</td>\n",
       "      <td>he hoped there would be stew for dinner turnip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stuffered into you, his belly counseled him.</td>\n",
       "      <td>STUFF IT INTO YOU HIS BELLY COUNSELLED HIM</td>\n",
       "      <td>stuffered into you his belly counseled him</td>\n",
       "      <td>stuff it into you his belly counseled him</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After early nightfall the yellow lamps would l...</td>\n",
       "      <td>AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD L...</td>\n",
       "      <td>after early nightfall the yellow lamps would l...</td>\n",
       "      <td>after early nightfall the yellow lamps would l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello Bertie, any good in your mind?</td>\n",
       "      <td>HELLO BERTIE ANY GOOD IN YOUR MIND</td>\n",
       "      <td>hello bertie any good in your mind</td>\n",
       "      <td>hello bertie any good in your mind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Number 10. Fresh Nelly is waiting on you. Good...</td>\n",
       "      <td>NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD ...</td>\n",
       "      <td>number 10 fresh nelly is waiting on you good n...</td>\n",
       "      <td>number 10 fresh nelly is waiting on you good n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>Oh, to shoot my soul's full meaning into futur...</td>\n",
       "      <td>OH TO SHOOT MY SOUL'S FULL MEANING INTO FUTURE...</td>\n",
       "      <td>0 to shoot my soul is full meaning into future...</td>\n",
       "      <td>0 to shoot my soul is full meaning into future...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>Then I, long tried by natural ills, received t...</td>\n",
       "      <td>THEN I LONG TRIED BY NATURAL ILLS RECEIVED THE...</td>\n",
       "      <td>then i long tried by natural ills received the...</td>\n",
       "      <td>then i long tried by natural ills received the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>I love thee freely as men strive for right. I ...</td>\n",
       "      <td>I LOVE THEE FREELY AS MEN STRIVE FOR RIGHT I L...</td>\n",
       "      <td>i love thee freely as men strive for right i l...</td>\n",
       "      <td>i love thee freely as men strive for right i l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>I love thee with the passion put to use, in my...</td>\n",
       "      <td>I LOVE THEE WITH THE PASSION PUT TO USE IN MY ...</td>\n",
       "      <td>i love thee with the passion put to use in my ...</td>\n",
       "      <td>i love thee with the passion put to use in my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>I love thee with the love I seemed to lose wit...</td>\n",
       "      <td>I LOVE THEE WITH A LOVE I SEEMED TO LOSE WITH ...</td>\n",
       "      <td>i love thee with the love i seemed to lose wit...</td>\n",
       "      <td>i love thee with a love i seemed to lose with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2620 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             hypothesis  \\\n",
       "0     He hoped there would be stew for dinner, turni...   \n",
       "1          Stuffered into you, his belly counseled him.   \n",
       "2     After early nightfall the yellow lamps would l...   \n",
       "3                  Hello Bertie, any good in your mind?   \n",
       "4     Number 10. Fresh Nelly is waiting on you. Good...   \n",
       "...                                                 ...   \n",
       "2615  Oh, to shoot my soul's full meaning into futur...   \n",
       "2616  Then I, long tried by natural ills, received t...   \n",
       "2617  I love thee freely as men strive for right. I ...   \n",
       "2618  I love thee with the passion put to use, in my...   \n",
       "2619  I love thee with the love I seemed to lose wit...   \n",
       "\n",
       "                                              reference  \\\n",
       "0     HE HOPED THERE WOULD BE STEW FOR DINNER TURNIP...   \n",
       "1            STUFF IT INTO YOU HIS BELLY COUNSELLED HIM   \n",
       "2     AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD L...   \n",
       "3                    HELLO BERTIE ANY GOOD IN YOUR MIND   \n",
       "4     NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD ...   \n",
       "...                                                 ...   \n",
       "2615  OH TO SHOOT MY SOUL'S FULL MEANING INTO FUTURE...   \n",
       "2616  THEN I LONG TRIED BY NATURAL ILLS RECEIVED THE...   \n",
       "2617  I LOVE THEE FREELY AS MEN STRIVE FOR RIGHT I L...   \n",
       "2618  I LOVE THEE WITH THE PASSION PUT TO USE IN MY ...   \n",
       "2619  I LOVE THEE WITH A LOVE I SEEMED TO LOSE WITH ...   \n",
       "\n",
       "                                       hypothesis_clean  \\\n",
       "0     he hoped there would be stew for dinner turnip...   \n",
       "1            stuffered into you his belly counseled him   \n",
       "2     after early nightfall the yellow lamps would l...   \n",
       "3                    hello bertie any good in your mind   \n",
       "4     number 10 fresh nelly is waiting on you good n...   \n",
       "...                                                 ...   \n",
       "2615  0 to shoot my soul is full meaning into future...   \n",
       "2616  then i long tried by natural ills received the...   \n",
       "2617  i love thee freely as men strive for right i l...   \n",
       "2618  i love thee with the passion put to use in my ...   \n",
       "2619  i love thee with the love i seemed to lose wit...   \n",
       "\n",
       "                                        reference_clean  \n",
       "0     he hoped there would be stew for dinner turnip...  \n",
       "1             stuff it into you his belly counseled him  \n",
       "2     after early nightfall the yellow lamps would l...  \n",
       "3                    hello bertie any good in your mind  \n",
       "4     number 10 fresh nelly is waiting on you good n...  \n",
       "...                                                 ...  \n",
       "2615  0 to shoot my soul is full meaning into future...  \n",
       "2616  then i long tried by natural ills received the...  \n",
       "2617  i love thee freely as men strive for right i l...  \n",
       "2618  i love thee with the passion put to use in my ...  \n",
       "2619  i love thee with a love i seemed to lose with ...  \n",
       "\n",
       "[2620 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"hypothesis_clean\"] = [normalizer(text) for text in data[\"hypothesis\"]]\n",
    "data[\"reference_clean\"] = [normalizer(text) for text in data[\"reference\"]]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EBGSITeBYPTT",
    "outputId": "7b3dbe7c-a37e-4a07-a50a-b27d5f88b68f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 4.26 %\n"
     ]
    }
   ],
   "source": [
    "wer = jiwer.wer(list(data[\"reference_clean\"]), list(data[\"hypothesis_clean\"]))\n",
    "\n",
    "print(f\"WER: {wer * 100:.2f} %\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "039b53f2702c4179af7e0548018d0588": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "06b9aa5f49fa44ba8c93b647dc7db224": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0d10a42c753453283e5219c22239337",
      "max": 164,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09f4cb79ff86465aaf48b0de24869af9",
      "value": 164
     }
    },
    "09a29a91f58d4462942505a3cc415801": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_83391f98a240490987c397048fc1a0d4",
       "IPY_MODEL_06b9aa5f49fa44ba8c93b647dc7db224",
       "IPY_MODEL_da9c231ee67047fb89073c95326b72a5"
      ],
      "layout": "IPY_MODEL_48da931ebe7f4fd299f8c98c7d2460ff"
     }
    },
    "09f4cb79ff86465aaf48b0de24869af9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1b9cecf5b3584fba8258a81d4279a25b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39f5a6ae8ba74c8598f9c6d5b8ad2d65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48da931ebe7f4fd299f8c98c7d2460ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a901f447c1d477bb49f954e0feacedd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83391f98a240490987c397048fc1a0d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a901f447c1d477bb49f954e0feacedd",
      "placeholder": "​",
      "style": "IPY_MODEL_39f5a6ae8ba74c8598f9c6d5b8ad2d65",
      "value": "100%"
     }
    },
    "a0d10a42c753453283e5219c22239337": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da9c231ee67047fb89073c95326b72a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b9cecf5b3584fba8258a81d4279a25b",
      "placeholder": "​",
      "style": "IPY_MODEL_039b53f2702c4179af7e0548018d0588",
      "value": " 164/164 [05:08&lt;00:00,  1.86s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
